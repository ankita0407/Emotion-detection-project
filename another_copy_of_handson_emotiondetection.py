# -*- coding: utf-8 -*-
"""Another copy of HandsOn_EmotionDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lb7fwLOoSJsMVsE4oRpY45-bL4NnSW9u
"""

!sudo apt update
!sudo apt install libgtk2.0-dev pkg-config libgl1-mesa-glx
!pip uninstall opencv-python
!pip install opencv-python
!pip install deepface

from IPython.display import display, Javascript
from google.colab.output import eval_js
import cv2
import base64
import numpy as np
import matplotlib.pyplot as plt
from deepface import DeepFace

def take_photo(filename='photo.jpg', quality=0.8):
    js = Javascript('''
        async function takePhoto(quality) {
            const div = document.createElement('div');
            const capture = document.createElement('button');
            capture.textContent = 'üì∑ Capture';
            div.appendChild(capture);

            const video = document.createElement('video');
            video.style.display = 'block';
            div.appendChild(video);
            document.body.appendChild(div);

            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
            await video.play();

            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

            await new Promise((resolve) => capture.onclick = resolve);

            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);

            stream.getTracks().forEach(track => track.stop());
            div.remove();

            return canvas.toDataURL('image/jpeg', quality);
        }
    ''')
    display(js)
    data = eval_js("takePhoto({})".format(quality))
    binary = base64.b64decode(data.split(',')[1])
    with open(filename, 'wb') as f:
        f.write(binary)
    return filename

image_path = take_photo()
print("Image captured to:", image_path)

# Read image from disk
img = cv2.imread(image_path)

# Check if image was loaded
if img is None:
    print("‚ùå Error: Image not found or invalid!")
else:
    # Run emotion detection
    try:
        result = DeepFace.analyze(img, actions=['emotion'], enforce_detection=False)
        emotion = result[0]['dominant_emotion']
        print("‚úÖ Detected Emotion:", emotion)

        # Display image with emotion
        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        plt.title(f"Emotion: {emotion}")
        plt.axis('off')
        plt.show()

    except Exception as e:
        print("‚ùå Emotion detection failed:", str(e))

